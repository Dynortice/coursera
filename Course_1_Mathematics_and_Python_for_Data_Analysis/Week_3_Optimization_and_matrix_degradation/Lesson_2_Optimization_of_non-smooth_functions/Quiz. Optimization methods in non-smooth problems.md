1. Какие из перечисленных подходов к задаче поиска минимума не требуют существования градиента у оптимизируемой функции?
  * Метод имитации отжига
  * Дифференциальная эволюция
2. Как вы думаете, зачем нужна стадия мутации в генетических алгоритмах?
  * Чтобы популяция не вырождалась слишком быстро в набор очень похожих друг на друга векторов и был некоторый шанс выбивания из локальных минимумов
3. Почему при поиске минимума методом имитации отжига допускаются переходы в точки, в которых функция принимает большие значения, нежели в текущей?
  * Чтобы метод мог иногда выбираться из локальных минимумов
4. В каких случаях стоит применять методы оптимизации, не использующие градиент?
  * В случаях, когда у функции нет градиента, т.к. в случае его наличия скорее всего неградиентному методу потребуется больше итераций или вычислений значения функции, чем градиентному. А также в случаях, когда нужно найти глобальный экстремум функции, а градиентные методы скорее всего будут попадать в локальный.
